{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“¦ MEGA-MODEL TRAINING (Merged Datasets)\n",
                "This notebook combines 3 datasets into one SUPER dataset:\n",
                "1.  Cardboard Box (Small)\n",
                "2.  Cardboard Box (Medium)\n",
                "3.  Logistics (Massive - Filtered for Boxes only)\n",
                "\n",
                "### Steps:\n",
                "1.  **Runtime -> Change runtime type -> T4 GPU**.\n",
                "2.  Run all cells."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install & Setup\n",
                "%pip install ultralytics roboflow\n",
                "import os\n",
                "import shutil\n",
                "from roboflow import Roboflow\n",
                "from ultralytics import YOLO\n",
                "\n",
                "# Create a clean 'mega_dataset' folder\n",
                "if os.path.exists('mega_dataset'): shutil.rmtree('mega_dataset')\n",
                "os.makedirs('mega_dataset/train/images', exist_ok=True)\n",
                "os.makedirs('mega_dataset/train/labels', exist_ok=True)\n",
                "os.makedirs('mega_dataset/valid/images', exist_ok=True)\n",
                "os.makedirs('mega_dataset/valid/labels', exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Download Datasets (User Provided Codes)\n",
                "rf = Roboflow(api_key=\"9Dro6WbBZ9bW4iaU1Z53\")\n",
                "\n",
                "# Dataset 1: Cardboard Box 1\n",
                "print(\"Downloading Dataset 1...\")\n",
                "d1 = rf.workspace(\"project-wfbsj\").project(\"cardboard-box-8uolq\").version(1).download(\"yolov8\")\n",
                "\n",
                "# Dataset 2: Cardboard Box 2\n",
                "print(\"Downloading Dataset 2...\")\n",
                "d2 = rf.workspace(\"cardboard-box\").project(\"cardboard-box-hql8b\").version(1).download(\"yolov8\")\n",
                "\n",
                "# Dataset 3: Logistics (Big One)\n",
                "print(\"Downloading Dataset 3 (Logistics)...\")\n",
                "d3 = rf.workspace(\"roboflow-ngkro\").project(\"logistics-h0uec\").version(10).download(\"yolov8\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. MERGE LOGIC (The Magic Step)\n",
                "# We copy all files into 'mega_dataset'.\n",
                "# Key: The Logistics dataset keeps class names in 'data.yaml'. \n",
                "# We will SIMPLIFY everything to just 1 class: 'box' (Index 0).\n",
                "\n",
                "def merge_dataset(source_folder, is_logistics=False):\n",
                "    for split in ['train', 'valid']:\n",
                "        # Images\n",
                "        src_img = f\"{source_folder}/{split}/images\"\n",
                "        dst_img = f\"mega_dataset/{split}/images\"\n",
                "        if os.path.exists(src_img):\n",
                "            for f in os.listdir(src_img):\n",
                "                shutil.copy(f\"{src_img}/{f}\", f\"{dst_img}/{source_folder}_{f}\")\n",
                "        \n",
                "        # Labels (Rewriting Class ID to 0)\n",
                "        src_lbl = f\"{source_folder}/{split}/labels\"\n",
                "        dst_lbl = f\"mega_dataset/{split}/labels\"\n",
                "        if os.path.exists(src_lbl):\n",
                "            for f in os.listdir(src_lbl):\n",
                "                with open(f\"{src_lbl}/{f}\", 'r') as file:\n",
                "                    lines = file.readlines()\n",
                "                \n",
                "                new_lines = []\n",
                "                for line in lines:\n",
                "                    parts = line.strip().split()\n",
                "                    cls = int(parts[0])\n",
                "                    \n",
                "                    # For Logistics, 'cardboard box' is class 2. We skip others.\n",
                "                    if is_logistics:\n",
                "                        if cls == 2: # 2 is usually box in this list\n",
                "                            # CHANGE to 0 (Unified Class)\n",
                "                            new_lines.append(f\"0 {' '.join(parts[1:])}\\n\")\n",
                "                    else:\n",
                "                        # For standard box datasets, assume everything is a box (Class 0)\n",
                "                        new_lines.append(f\"0 {' '.join(parts[1:])}\\n\")\n",
                "                \n",
                "                if new_lines: # Only save if we found a box\n",
                "                    with open(f\"{dst_lbl}/{source_folder}_{f}\", 'w') as file:\n",
                "                        file.writelines(new_lines)\n",
                "\n",
                "print(\"Merging Datasets...\")\n",
                "merge_dataset(d1.location, is_logistics=False)\n",
                "merge_dataset(d2.location, is_logistics=False)\n",
                "merge_dataset(d3.location, is_logistics=True)\n",
                "print(\"Merge Complete!\")\n",
                "\n",
                "# Create data.yaml\n",
                "yaml_content = \"\"\"\n",
                "train: ../train/images\n",
                "val: ../valid/images\n",
                "\n",
                "nc: 1\n",
                "names: ['cardboard_box']\n",
                "\"\"\"\n",
                "with open(\"mega_dataset/data.yaml\", \"w\") as f:\n",
                "    f.write(yaml_content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. TRAIN (The Result)\n",
                "!yolo detect train data=mega_dataset/data.yaml model=yolov8n.pt epochs=20 imgsz=640 name=yolov8n_mega_box"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Download\n",
                "from google.colab import files\n",
                "files.download('/content/runs/detect/yolov8n_mega_box/weights/best.pt')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}